{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpEqsZpRKtkE"
      },
      "source": [
        "This notebook is associated with Assignment 1. Use it to complete the assignment by following the instructions provided in each section, which includes a text cell describing the requirements. For additional details, see the Canvas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwGBUHRSKvf1"
      },
      "source": [
        "Use this first cell to import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "taBOSk4HKwZp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scipy.stats import t\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hglJVRRslqMn"
      },
      "source": [
        "# 1. **Data Management**\n",
        "\n",
        "\n",
        "In this part, you need to:\n",
        "\n",
        "1.   analyse and prepare the data. Use plots, graphs, and tables (such as histogram, box plots, scatterplots etc.) to better analyse the dataset and identify issues or potential improvements in the data, including (but not limited to) unnecessary feature/variable which can be dropped/removed, standardization, encoding, etc;\n",
        "2.   split the data and define your experimental protocol (such as cross-validation or k-fold)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szQFlMDMJYEh"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "def load_data(filepath):\n",
        "    print(\"Loading data...\")\n",
        "    df = pd.read_csv(filepath)\n",
        "    print(f\"Data loaded with {df.shape[0]} rows and {df.shape[1]} columns.\\n\")\n",
        "    return df\n",
        "\n",
        "# Check for Missing Values\n",
        "def check_missing(df):\n",
        "    print(\"Checking for missing values...\")\n",
        "    missing = df.isnull().sum()\n",
        "    if missing.sum() > 0:\n",
        "        print(missing[missing > 0])\n",
        "    else:\n",
        "        print(\"No missing values found.\")\n",
        "    print(\"\")\n",
        "\n",
        "# Visualize Outliers\n",
        "def show_outliers(df, ignore_cols):\n",
        "    print(\"Visualizing outliers...\")\n",
        "    plt.figure(figsize=(12,6))\n",
        "    sns.boxplot(data=grades_data, color='#00ff99')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title('Box Plots to Visualise outliers')\n",
        "    plt.show()\n",
        "    print(\"\")\n",
        "\n",
        "# Remove Outliers\n",
        "def clean_outliers(df, ignore_cols):\n",
        "    print(\"Removing outliers...\")\n",
        "    original_shape = df.shape[0]\n",
        "    for col in df.select_dtypes(include=['number']).columns:\n",
        "        if col not in ignore_cols:\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower = Q1 - 1.5 * IQR\n",
        "            upper = Q3 + 1.5 * IQR\n",
        "            df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
        "    print(f\"Outliers removed, new dataset size: {df.shape[0]} rows (removed {original_shape - df.shape[0]} rows).\\n\")\n",
        "    return df.reset_index(drop=True)\n",
        "\n",
        "# Encode Categories\n",
        "def encode_categories(df, categorical_cols):\n",
        "    print(\"Encoding categorical variables...\")\n",
        "    encoder = LabelEncoder()\n",
        "    for col in categorical_cols:\n",
        "        df[col] = encoder.fit_transform(df[col])\n",
        "    print(\"\")\n",
        "    return df\n",
        "\n",
        "# Create Pass/Fail Target\n",
        "def make_pass_fail(df):\n",
        "    df['Pass'] = (df['Grade'] >= 12).astype(int)\n",
        "    return df.drop(columns=['Grade'])\n",
        "\n",
        "# Correlation Heatmap\n",
        "def show_correlation(df, target_col):\n",
        "    print(\"Visualizing correlation heatmap...\")\n",
        "    corr_matrix = df.corr()\n",
        "    plt.figure(figsize=(20, 16))\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title(\"Correlation Heatmap\")\n",
        "    plt.show()\n",
        "    print(\"\")\n",
        "\n",
        "# Remove Weak Features\n",
        "def remove_weak_features(df, target_col, alpha=0.01):\n",
        "    print(\"Removing weakly correlated features...\")\n",
        "    corr_series = df.corr()[target_col].drop(target_col)\n",
        "    n = len(df)\n",
        "    critical_value = t.ppf(1 - alpha / 2, n - 2) / np.sqrt(n - 2 + t.ppf(1 - alpha / 2, n - 2) ** 2)\n",
        "    threshold = round(critical_value, 3)\n",
        "    relevant_cols = [target_col] + list(corr_series[abs(corr_series) > threshold].index)\n",
        "    excluded_cols = list(corr_series[abs(corr_series) <= threshold].index)\n",
        "    print(\"Excluded Columns due to Weak Correlation:\", excluded_cols)\n",
        "    print(f\"Remaining columns: {len(relevant_cols)}\\n\")\n",
        "    return df[relevant_cols]\n",
        "\n",
        "# Main Program\n",
        "grades_data = load_data('grades.csv')\n",
        "categorical_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
        "ignore_outlier_cols = ['failures', 'Grade']\n",
        "check_missing(grades_data)\n",
        "show_outliers(grades_data, ignore_outlier_cols)\n",
        "grades_data = clean_outliers(grades_data, ignore_outlier_cols)\n",
        "grades_data = encode_categories(grades_data, categorical_cols)\n",
        "grades_data = make_pass_fail(grades_data)\n",
        "show_correlation(grades_data, 'Pass')\n",
        "grades_data = remove_weak_features(grades_data, 'Pass')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScTrpUW8zOp4"
      },
      "source": [
        "---\n",
        "\n",
        "# 2. **Model Training**\n",
        "\n",
        "Here, you need to:\n",
        "\n",
        "1.\tselect and compare at least three machine learning models (seen/discussed during the lectures) appropriate for your modelling;\n",
        "2.\tif there are hyperparameters in a selected algorithm, define a hyperparameter search protocol (you can define your own), and tune them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJs8HpW_zX0M"
      },
      "outputs": [],
      "source": [
        "# Write your proposed solution code here. Create more code cells if you find it necessary\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RBW58of0ZDo"
      },
      "source": [
        "---\n",
        "\n",
        "# 3. **Evaluate models**\n",
        "\n",
        "Here, you need to:\n",
        "\n",
        "1.\ttest the model (the best one you obtained from the above stage) on the testing dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHWwdXg32BEl"
      },
      "outputs": [],
      "source": [
        "# Write your proposed solution code here. Create more code cells if you find it necessary\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
